{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now You Code In Class: Searching Log Data\n",
    "\n",
    "## What is log data?\n",
    "\n",
    "When an application runs, there are commonly two kinds of output:\n",
    "\n",
    "- **user output** is visible to the individuals running / using the application\n",
    "- **logging output** is collected but not seen by the user. It captures events like errors, or informational messages to help a programmer debug the application in use.\n",
    "\n",
    "In this assignment we will look at logging data from 4 different big data applications.\n",
    "\n",
    "- **HDFS** - a distributed file-storage system\n",
    "- **Hadoop** - a distributed compute framework\n",
    "- **Spark** - a high-performance distributed compute enviornment \n",
    "- **Zookeeper** - a orchestrator. It manages distributed applications.\n",
    "\n",
    "We will use Python to read and process the log files. What the applications actually do is irrelevant to the exercise, but if you are interested, the iSchool does have a course: IST469: Advanced Big Data Management. This course covers big data; distributed database systems at scale.\n",
    "\n",
    "## The task\n",
    "\n",
    "In this assignment we will write a program to search through the logs for specific text. This will make it easier for a person supporting these applications to find problems or issues.\n",
    "\n",
    "The program will output the rows in the logs matching the text in addition to the number of rows returned.\n",
    "\n",
    "### Getting the Logs\n",
    "\n",
    "We will retrieve our logs from the internet courtsey of the Loghub project, here:\n",
    "\n",
    "    Jieming Zhu, Shilin He, Pinjia He, Jinyang Liu, Michael R. Lyu. Loghub: A Large Collection of System Log Datasets for AI-driven Log Analytics. IEEE International Symposium on Software Reliability Engineering (ISSRE), 2023.\n",
    "    \n",
    "Run the code cell below to retrieve the log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl https://raw.githubusercontent.com/logpai/loghub/master/Zookeeper/Zookeeper_2k.log -o Zookeeper_2k.log\n",
    "! curl https://raw.githubusercontent.com/logpai/loghub/master/HDFS/HDFS_2k.log -o HDFS_2k.log\n",
    "! curl https://raw.githubusercontent.com/logpai/loghub/master/Hadoop/Hadoop_2k.log -o Hadoop_2k.log\n",
    "! curl https://raw.githubusercontent.com/logpai/loghub/master/Spark/Spark_2k.log -o Spark_2k.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our recommended approach : Top-Down, Successive Refinement\n",
    "\n",
    "To solve this problem we will use a \"top down\" approach. In this method you write your algorithm and don't worry about complex steps. One step in the algorithm is very likely NOT a single line of Python.\n",
    "\n",
    "As part of succesive refinement, we break up the complex steps into simpler steps. These are usually written as functions. \n",
    "\n",
    "\n",
    "##  Step 1: Problem Analysis for the program\n",
    "\n",
    "Inputs (be specific as possible): \n",
    "\n",
    "    PROMPT 1 (two inputs)\n",
    "\n",
    "Outputs (again be specific as possible): \n",
    "\n",
    "    PROMPT 2 (two outputs)\n",
    "\n",
    "Algorithm (Steps in Program):\n",
    "\n",
    "    PROMPT 3\n",
    "    - Hint: Which approach to file processing? All at once or a line at a time?\n",
    "    \n",
    "\n",
    "Which steps need to be refined?\n",
    "\n",
    "    PROMPT 4 (hint: two processes)\n",
    "\n",
    "\n",
    "Next, we write the refinements as functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2a: Write the `readfile()` function\n",
    "\n",
    "Now we write the refinements as functions. First we start with `readfile()`. \n",
    "\n",
    "### Problem Analysis was done for you\n",
    "\n",
    "    INPUT: file to read\n",
    "    OUTPUT: lines in the file as an iterable\n",
    "    \n",
    "    ALGO:\n",
    "        - open file for reading\n",
    "        - read lines\n",
    "        - return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PROMPT 5: Write function definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2b: Write tests for `readfile()` function\n",
    "\n",
    "Let's make sure the function works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT 6 Test(s) for function.\n",
    "# Some Code Written for you\n",
    "\n",
    "# Arrange: Setup inputs and expected\n",
    "expected_line_count = ???\n",
    "filename = ???\n",
    "\n",
    "# Act: Call function under test, get actual_line_count\n",
    "\n",
    "\n",
    "# Assert\n",
    "print(f\"For {filename}, EXPECT={expected_line_count}, ACTUAL={actual_line_count}\")\n",
    "assert expected_line_count == actual_line_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ## Step 3a: Problem Analysis for `match()`\n",
    "\n",
    "Inputs: \n",
    "\n",
    "    PROMPT 7: What inputs are necessary to make a match?\n",
    "    \n",
    "Outputs: \n",
    "\n",
    "    PROMPT 8: What is the output of the match?\n",
    "    \n",
    "\n",
    "Algorithm (Steps in Program):\n",
    "\n",
    "    PROMPT 9\n",
    "    \n",
    "\n",
    "How many tests are required and why?\n",
    "\n",
    "    PROMPT 10\n",
    "\n",
    "\n",
    "## Step 3b: Code the function `match()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT 11 - write function: Use A doc string and type hints this time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3c: Write tests for the function `match()`\n",
    "\n",
    "Let's make sure the function works, test both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT 12 - write test(s) for function\n",
    "\n",
    "# Case #1 True\n",
    "# Arrange: inputs + expectation\n",
    "\n",
    "# Act: Function under test?\n",
    "\n",
    "# Asseert\n",
    "print(f\"For TEXT={text}, LINE={line} EXPECT={expect}, ACTUAL={actual}\")\n",
    "assert expect == actual\n",
    "\n",
    "# Case #2 False\n",
    "# Arrange\n",
    "\n",
    "# Act\n",
    "\n",
    "# Asseert\n",
    "print(f\"For TEXT={text}, LINE={line} EXPECT={expect}, ACTUAL={actual}\")\n",
    "assert expect == actual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Write the Program\n",
    "\n",
    "- Use your plan from Step 1 above\n",
    "- use `readfile()` to read in the file in question\n",
    "- use `match()` to check for matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT 13 - write main program using `print()` and `input()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Final Program as an Interact\n",
    "\n",
    "Use `@interact_manual` to generate input widgets for this program. provide a list of files to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT 14\n",
    "from ipywidgets import interact_manual\n",
    "files = ['HDFS_2k.log','Hadoop_2k.log','Spark_2k.log','Zookeeper_2k.log']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from casstools.assignment import Assignment\n",
    "Assignment().submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
